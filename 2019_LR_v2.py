# -*- coding: utf-8 -*-
"""Copy of 551_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FcIY2oMwx5OJE4zZV-Bnzuykn1PHi7Gl

**1. Importing Packages:**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import scipy as sc
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import timeit
# %matplotlib inline

"""**2. Importing Data Sets**"""

# Importing bankruptcy.csv and storing the dataset in panda repository
url_bankruptcy = 'https://raw.githubusercontent.com/yuktathapliyal/551_1/master/bankrupcy.csv'
df1 = pd.read_csv(url_bankruptcy)
df1.head()

df1.hist(column='ClassLabel')

# Importing hepatits.csv and storing the dataset in panda repository
url_hepatitis = 'https://raw.githubusercontent.com/yuktathapliyal/551_1/master/hepatitis.csv'
df2 = pd.read_csv(url_hepatitis)
df2.head()

df2.hist(column='ClassLabel')

desc = df2.describe() 
desc

df2.groupby('ClassLabel').boxplot(column='age')

"""**3. Data Pre-Processing**"""

# Dataset 1
df_temp_1 = df1.copy()

train_1 = df_temp_1.sample(frac=0.8,random_state=200)
test_1 = df_temp_1.drop(train_1.index)

#Normalisation
norm = MinMaxScaler().fit(train_1)
xtrain_1_NORM = norm.transform(train_1)
xtest_1_NORM = norm.transform(test_1)

ytrain_1 = train_1['ClassLabel']
train_1.drop('ClassLabel', inplace=True, axis=1)

ytest_1 = test_1['ClassLabel']
test_1.drop('ClassLabel', inplace=True, axis=1)

ytrain_1 = ytrain_1.to_numpy()
xtrain_1 = train_1.to_numpy()
ytest_1 = ytest_1.to_numpy()
xtest_1 = test_1.to_numpy()

#Adding polynomial features for selected columns
poly_features =  dict({1: 5, 2: 12, 3:15, 4:26, 5:27, 6:29, 7:31, 8:36, 9:46, 10:51, 11:53, 12:57, 13:59, 14:61}) 

for i in poly_features:
  col_select = poly_features[i]

  col_sq_train = np.power(xtrain_1[:,col_select],2)
  col_sq_test = np.power(xtest_1[:,col_select],2)

  xtrain_1 = np.c_[xtrain_1,col_sq_train]
  xtest_1 =  np.c_[xtest_1,col_sq_test]



n = xtest_1.shape[0]
xtest_1 = np.c_[ xtest_1, np.ones(n) ] 

ytrain_1 = ytrain_1.reshape((ytrain_1.shape[0],1))
ytest_1 = ytest_1.reshape((ytest_1.shape[0],1))

#Dataset 2
df_temp_2 = df2.copy()
train_2 = df_temp_2.sample(frac=0.8,random_state=200)
test_2 = df_temp_2.drop(train_2.index)

ytrain_2 = train_2['ClassLabel']
train_2.drop('ClassLabel', inplace=True, axis=1)
ytest_2 = test_2['ClassLabel']
test_2.drop('ClassLabel', inplace=True, axis=1)
ytrain_2 = ytrain_2.to_numpy()
xtrain_2 = train_2.to_numpy()
ytest_2 = ytest_2.to_numpy()
xtest_2 = test_2.to_numpy()

poly_features_2 =  dict({1: 14, 2:15, 3:17, 4:0, 5:16, 6:13 }) 

for i in poly_features_2:
  col_select = poly_features_2[i]

  col_sq_train = np.power(xtrain_2[:,col_select],2)
  col_sq_test = np.power(xtest_2[:,col_select],2)

  xtrain_2 = np.c_[xtrain_2,col_sq_train]
  xtest_2 =  np.c_[xtest_2,col_sq_test]


n = xtest_2.shape[0]
xtest_2 = np.c_[ xtest_2, np.ones(n) ] 
ytrain_2 = ytrain_2.reshape((ytrain_2.shape[0],1))
ytest_2 = ytest_2.reshape((ytest_2.shape[0],1))

"""**4. Algorithm**"""

def sigmoid(z):
  sig = 1.0 / ( 1.0 + np.exp(- z))
  return sig

def parameters(xtrain):
  n = xtrain.shape[0]
  m = xtrain.shape[1]

  X = np.c_[ xtrain, np.ones(n) ] 
  w = np.zeros((m + 1, 1))

  return X, w

def cross_entropy(X, y, w, lambd):
  
  a = sigmoid( X @ w  ) 
  
  CE =  ((-1) *  np.sum( (y*(np.log(a))) + ((1-y) * np.log(1-a))) ) + (lambd*np.sum(w[:-1]))
  w_temp = w
  w_temp[-1] = 0
  grad_vector = (-1) * (X.T @ (a-y)) + (lambd*w_temp)
  
  return CE, grad_vector

def gradient_descent(X, y, w, iterations, learning_rate, lambd):
  
  CEs = []

  for i in range(iterations):
        
        CE, dw = cross_entropy(X, y, w, lambd)
        
        w = w + ( learning_rate * dw )
            
  return w, dw, CEs

def prediction(X, w):

  a = sigmoid(np.dot(X,w))
  p =  (a>=0.5)*1;
  
  return p

def logistic_regression(xtrain, ytrain, xtest, ytest, iterations, learning_rate, lambd):
  X, w = parameters(xtrain)
  
  w_new, dw, CE = gradient_descent(X, ytrain, w, iterations, learning_rate, lambd)
  
  ytrain_prediction = prediction(X, w_new)
  ytest_prediction = prediction(xtest , w_new)
 
  print("train accuracy: {} %".format(100 - np.mean(np.abs(ytrain_prediction - ytrain)) * 100))
  print("test accuracy: {} %".format(100 - np.mean(np.abs(ytest_prediction - ytest)) * 100))

print("Dataset 1\n")
t1 = timeit.default_timer()
lr_1_1 = logistic_regression(xtrain_1, ytrain_1, xtest_1, ytest_1, iterations = 9000, learning_rate = 0.005, lambd = 0)
t2 = timeit.default_timer()
print('Run Time: seconds', (t2-t1) ,'seconds')
print("\nDataset 1\n")
t3 = timeit.default_timer()
lr_1_2 = logistic_regression(xtrain_2, ytrain_2, xtest_2, ytest_2, iterations = 1, learning_rate = 0.005, lambd = 0)
t4 = timeit.default_timer()
print('Run Time: seconds', (t4-t3) ,'seconds')